
<!-- saved from url=(0038)https://imankgoyal.github.io/ifor.html -->
<html data-darkreader-mode="dynamic" data-darkreader-scheme="dark"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><style class="darkreader darkreader--fallback" media="screen"></style><style class="darkreader darkreader--text" media="screen"></style><style class="darkreader darkreader--invert" media="screen">.jfk-bubble.gtx-bubble, .captcheck_answer_label > input + img, span#closed_text > img[src^="https://www.gstatic.com/images/branding/googlelogo"], span[data-href^="https://www.hcaptcha.com/"] > #icon, #bit-notification-bar-iframe, ::-webkit-calendar-picker-indicator {
    filter: invert(100%) hue-rotate(180deg) contrast(75%) !important;
}</style><style class="darkreader darkreader--inline" media="screen">[data-darkreader-inline-bgcolor] {
  background-color: var(--darkreader-inline-bgcolor) !important;
}
[data-darkreader-inline-bgimage] {
  background-image: var(--darkreader-inline-bgimage) !important;
}
[data-darkreader-inline-border] {
  border-color: var(--darkreader-inline-border) !important;
}
[data-darkreader-inline-border-bottom] {
  border-bottom-color: var(--darkreader-inline-border-bottom) !important;
}
[data-darkreader-inline-border-left] {
  border-left-color: var(--darkreader-inline-border-left) !important;
}
[data-darkreader-inline-border-right] {
  border-right-color: var(--darkreader-inline-border-right) !important;
}
[data-darkreader-inline-border-top] {
  border-top-color: var(--darkreader-inline-border-top) !important;
}
[data-darkreader-inline-boxshadow] {
  box-shadow: var(--darkreader-inline-boxshadow) !important;
}
[data-darkreader-inline-color] {
  color: var(--darkreader-inline-color) !important;
}
[data-darkreader-inline-fill] {
  fill: var(--darkreader-inline-fill) !important;
}
[data-darkreader-inline-stroke] {
  stroke: var(--darkreader-inline-stroke) !important;
}
[data-darkreader-inline-outline] {
  outline-color: var(--darkreader-inline-outline) !important;
}
[data-darkreader-inline-stopcolor] {
  stop-color: var(--darkreader-inline-stopcolor) !important;
}</style><style class="darkreader darkreader--variables" media="screen">:root {
   --darkreader-neutral-background: #232526;
   --darkreader-neutral-text: #cbc7c3;
   --darkreader-selection-background: #1355a4;
   --darkreader-selection-text: #d8d7d4;
}</style><style class="darkreader darkreader--root-vars" media="screen"></style><style class="darkreader darkreader--user-agent" media="screen">html {
    background-color: #28292a !important;
}
html {
    color-scheme: dark !important;
}
html, body, input, textarea, select, button {
    background-color: #28292a;
}
html, body, input, textarea, select, button {
    border-color: #756e63;
    color: #d8d7d4;
}
a {
    color: #3e8eec;
}
table {
    border-color: #5b6063;
}
::placeholder {
    color: #aaa49c;
}
input:-webkit-autofill,
textarea:-webkit-autofill,
select:-webkit-autofill {
    background-color: #5b6013 !important;
    color: #d8d7d4 !important;
}
::-webkit-scrollbar {
    background-color: #2e3132;
    color: #a49f95;
}
::-webkit-scrollbar-thumb {
    background-color: #4e5255;
}
::-webkit-scrollbar-thumb:hover {
    background-color: #5d6366;
}
::-webkit-scrollbar-thumb:active {
    background-color: #505558;
}
::-webkit-scrollbar-corner {
    background-color: #28292a;
}
::selection {
    background-color: #1355a4 !important;
    color: #d8d7d4 !important;
}
::-moz-selection {
    background-color: #1355a4 !important;
    color: #d8d7d4 !important;
}</style>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async="" src="./FOggyStereo_files/js"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-XD2JPS9KVL');
</script>

<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
  body {
    font-family: "Titillium Web","HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
    font-weight:300;
    font-size:18px;
    margin-left: auto;
    margin-right: auto;
    width: 1100px;
  }

  h1 {
    font-weight:300;
  }

  .disclaimerbox {
    background-color: #eee;
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
    padding: 20px;
  }

.paper-thumbnail {
    margin: 0 auto;
    width: 40%;
    max-width: 360px;
    display: inline-block;
    vertical-align: top;
    padding: 2% 0% 4% 3%;
}

.paper-info {
    width: 45%;
    display: inline-block;
    vertical-align: top;
    text-align: justify;
}
@media (max-width: 999px) {
    .paper-thumbnail {
        width: 60%;
    }

    .paper-info {
        width: 80%;
    }
}

pre {
    overflow-x: auto;
    text-align: left;
    border: 1px solid grey;
    border-radius: 3px;
    background: #eeeeee;
    padding: 5px 5px 5px 10px;
    line-height: 1.2;
    white-space: pre-wrap;
}

pre code {
    text-align: left;
    word-wrap: normal;
    white-space: pre-wrap;
    font-size: 16px;
}
  video.header-vid {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.header-img {
    height: 140px;
    border: 1px solid black;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  img.rounded {
    border: 1px solid #eeeeee;
    border-radius: 10px ;
    -moz-border-radius: 10px ;
    -webkit-border-radius: 10px ;
  }

  a:link,a:visited
  {
    color: #1367a7;
    text-decoration: none;
  }
  a:hover {
    color: #208799;
  }

  td.dl-link {
    height: 160px;
    text-align: center;
    font-size: 22px;
  }

  .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
            15px 15px 0 0px #fff, /* The fourth layer */
            15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
            20px 20px 0 0px #fff, /* The fifth layer */
            20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
            25px 25px 0 0px #fff, /* The fifth layer */
            25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
    margin-left: 10px;
    margin-right: 45px;
  }


  .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
    box-shadow:
            0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
            5px 5px 0 0px #fff, /* The second layer */
            5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
            10px 10px 0 0px #fff, /* The third layer */
            10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
    margin-top: 5px;
    margin-left: 10px;
    margin-right: 30px;
    margin-bottom: 5px;
  }

  .vert-cent {
    position: relative;
      top: 50%;
      transform: translateY(-50%);
  }

  hr
  {
    border: 0;
    height: 1px;
    background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
  }

  #authors td {
    padding-bottom:5px;
    padding-top:30px;
  }
</style><style class="darkreader darkreader--sync" media="screen"></style>

  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="icon" href="https://imankgoyal.github.io/FOggyStereo_files/icon.png">
  <title>FoggyStereo</title>
  <meta name="HandheldFriendly" content="True">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="darkreader" content="3d21cf394c2fbe5bf6ff184bd4e16d7d"><style class="darkreader darkreader--override" media="screen">.vimvixen-hint {
    background-color: #7c5a01 !important;
    border-color: #cba923 !important;
    color: #e2d8bd !important;
}
::placeholder {
    opacity: 0.5 !important;
}
a[href="https://coinmarketcap.com/"] > svg[width="94"][height="16"] > path {
    fill: var(--darkreader-neutral-text) !important;
}
#edge-translate-panel-body,
.MuiTypography-body1 {
    color: var(--darkreader-neutral-text) !important;
}
gr-main-header {
    background-color: #204550 !important;
}</style>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        <!--$表示行内元素，$$表示块状元素 -->
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
      },
      "HTML-CSS": { availableFonts: ["TeX"] }
    });
  </script>
  <!--加载MathJax的最新文件， async表示异步加载进来 -->
  <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js">
  </script>

</head>

<body data-new-gr-c-s-check-loaded="14.1052.0" data-gr-ext-installed="">
      <br>
      <center><span style="font-size:36px;font-weight:bold;">FoggyStereo: Stereo Matching with Fog Volume Representation</span></center><br>
      <center><span style="font-size:24px;">(Code Coming Soon)</span></center><br>
      <!-- <table align="center" width="900px">

      <tbody>
      <tr>
        <td align="center" width="180px">
		<center><span style="font-size:22px"><a href="https://imankgoyal.github.io/" target="_blank">Chengtang Yao<sup>1,2</sup></a></span></center></td>
        
        <td align="center" width="200px">
        <center><span style="font-size:22px"><a href="https://cs.gmu.edu/~amousavi/" target="_blank">Lidong Yu<sup>2/sup></a></span></center></td>
          
        <td align="center" width="180px">
        <center><span style="font-size:22px"><a href="https://cpaxton.github.io/about/" target="_blank">Chris Paxton<sup>1</sup></a></span></center></td>

        <td align="center" width="180px">
        <center><span style="font-size:22px"><a href="https://research.nvidia.com/person/yuwei-chao" target="_blank">Yu-Wei Chao<sup>1</sup></a></span></center></td>

        <td align="center" width="180px">
	<center><span style="font-size:22px"><a href="https://www.ri.cmu.edu/ri-people/brian-e-okorn/" target="_blank">Brian Okorn<sup>1</sup></a></span></center></td>
      </tr>
      </tbody></table> -->

      <table align="center">
          <tbody><tr>
        
        <td align="center" width="260px">
        <center><span style="font-size:22px"><a href="https://scholar.google.com/citations?user=6qLtVZIAAAAJ&hl=zh-CN" target="_blank">Chengtang Yao</a></span></center></td>
          
        <td align="center" width="260px">
        <center><span style="font-size:22px"><a href="https://lidongyv.github.io/" target="_blank">Lidong Yu</a></span></center></td>
      </tr>
      </tbody></table>
      
        <table align="center">
            <tbody><tr>
        
        <td align="center" width="260px">
        <center><span style="font-size:22px"><a href="https://github.com/YaoChengTang" target="_blank">[Code]</a></span></center></td>
            
        <td align="center" width="260px">
        <center><span style="font-size:22px"><a href="https://github.com/YaoChengTang" target="_blank">[Paper]</a></span></center></td>

        <td align="center" width="260px">
        <center><span style="font-size:22px"><a href="https://github.com/YaoChengTang" target="_blank">[Poster]</a></span></center></td>
        </tr>
        </tbody></table>

      

      <!-- <table align="center" width="700px">
          <tbody><tr>
		<td align="center" width="250px">
		<center><span style="font-size:20px"><sup>1</sup>Beijing Institute of Technology</span></center></td>
		<td align="center" width="250px">
		<center><span style="font-size:20px"><sup>2</sup>NIO</span></center></td>
          </tr>
      </tbody></table>

      <table align="center" width="700px">
          <tbody><tr>
		<td align="center" width="250px">
                <img src="./FOggyStereo_files/nvidia.png" width="25%">
		</td>
		<td align="center" width="250px">
                <img src="./FOggyStereo_files/princeton.png" width="15%">
		</td>
          </tr>
      </tbody></table> -->
      

      <!-- <table align="center" width="300px">
      <tbody><tr><td align="center" width="300px">
          <center><img src="./FOggyStereo_files/real_seq_1.gif" height="300px"><br></center>
      </td></tr>
      </tbody></table> -->
	
      <!-- <hr>
      <center><h1>TLDR</h1></center>
      <div style="width:900px; margin:0 auto; text-align:center; font-size: 20px">
	      ● Robotic system for vision based object rearragement system; Iteratively minimizes flow. <br> <br>
	      ● Input is RGBD images of the current and target scene; No privilaged information used. <br> <br>
	      ● Trained entirely in simulation; Zero-shot transfer to real world. <br> <br>
	      ● Tested on objects not seen during training. <br> <br>
      </div> -->
      <hr>

      <center>
      <h1>Abstract</h1>

      <div class="paper-info">
      <!-- <h4><a href="https://arxiv.org/abs/2202.00732">IFOR: Iterative Flow Minimization for Robotic Object Rearrangement</a></h4> -->
      <!-- <h5>
Ankit Goyal, Arsalan Mousavian, Chris Paxton, Yu-Wei Chao, Brian Okorn, Jia Deng and Dieter Fox
      </h5> -->
      <!-- <pre><code>@inproceedings{goyal2022ifor,
  title={IFOR: Iterative Flow Minimization for Robotic Object Rearrangement},
  author={Goyal, Ankit and  Mousavian, Arsalan and Paxton, Chris and Chao, Yu-Wei and Okorn, Brian and Deng, Jia and Fox, Dieter},
  booktitle={arXiv:2202.00732},
  year={2022}
}</code></pre> -->
        Stereo matching in foggy scenes is challenging as the scattering effect of fog blurs the image and makes the matching ambiguous. Prior methods deem the fog as noise and discard it before matching. Different from them, we propose to explore depth hints from fog and improve stereo matching via these hints. The exploration of depth hints is designed from the perspective of rendering. The rendering is conducted by reversing the atmospheric scattering process and removing the fog within a selected depth range. The quality of the rendered image reflects the correctness of the selected depth, as the closer it is to the real depth, the clearer the rendered image is. We introduce a fog volume representation to collect these depth hints from the fog. We construct the fog volume by stacking images rendered with depths computed from disparity candidates that are also used to build the cost volume. We fuse the fog volume with cost volume to rectify the ambiguous matching caused by fog. Experiments show that our fog volume representation significantly promotes the SOTA result on foggy scenes by 10% ～ 30% while maintaining a comparable performance in clear scenes.
      </div>

      <div class="paper-thumbnail">
        <!-- <a href="https://arxiv.org/abs/2202.00732"> -->
        <img width="100%" src="./FOggyStereo_files/Fig1.jpg" alt="Paper thumbnail.">
        </a>
        </div>
      </center>

      <!-- <hr>
      <center><h1>Summary</h1></center>
      <div style="width:900px; margin:0 auto; text-align:justify">
	Accurate object rearrangement from vision is a crucial problem for a wide variety of real-world robotics applications in unstructured environments. We propose IFOR, an end-to-end method for the challenging problem of object rearrangement for unknown objects given an RGBD image of the original and final scenes. First, we learn an optical flow model to estimate the relative transformation of the objects purely from synthetic data. This flow is then used in an iterative minimization algorithm to achieve accurate positioning of previously unseen objects. Crucially, we show that our method applies to cluttered scenes, and in the real world, while training only on synthetic data.
      </div> -->

      <br>
      <hr>
      <center><h1>Pipeline</h1></center>
          <center><a href="./FOggyStereo_files/method.png"><img src="./FOggyStereo_files/Model3.png" width="900px"></a><br></center>
      <br>
      <div style="width:900px; margin:0 auto; text-align:justify">
        The overview of our method. We extract the features from left and right images to build the cost volume via warping &#x24E6. We predict the atmospheric light $L_{\infty}$ and attenuation coefficient $\beta$ from the left image to render a series of images with different depth $Z_{i}$. The rendered images are concatenated along channel dimension and fused with cost volume for disparity estimation.
      </div>

      <hr>

      <center><h1>Comparison with Prior Work</h1></center>

        <div style="width:900px; margin:0 auto; text-align:justify">
            The comparison of algorithms on the SceneFlow dataset. We compare the results testing on clear data and foggy data. * represents our re-implementation results.
        </div>
        <table align="center" width="900px">
        <tbody><tr><td align="center" width="900px">
            <center><img src="./FOggyStereo_files/sceneflow.png" width="100%"><br></center>
        </td></tr>
        </tbody>
        </table>
        
        <br>
        <div style="width:900px; margin:0 auto; text-align:justify">
            The comparison of algorithms on KITTI 2015 and 2012 datasets. * represents our re-implementation results.
        </div>
        <table align="center" width="900px">
        <tbody><tr><td align="center" width="900px">
            <center><img src="./FOggyStereo_files/KITTI.png" width="100%"><br></center>
        </td></tr>
        </tbody>
        </table>

        <br>
        <div style="width:900px; margin:0 auto; text-align:justify">
            The comparison of algorithms on the clear data of PixelAccurateDepth dataset. * represents our re-implementation results.
        </div>
        <table align="center" width="900px">
        <tbody><tr><td align="center" width="900px">
            <center><img src="./FOggyStereo_files/PAD1.png" width="100%"><br></center>
        </td></tr>
        </tbody>
        </table>

        <br>
        <div style="width:900px; margin:0 auto; text-align:justify">
            The comparison of algorithms on the foggy data of PixelAccurateDepth dataset. * represents our re-implementation results.
        </div>
        <table align="center" width="900px">
        <tbody><tr><td align="center" width="900px">
            <center><img src="./FOggyStereo_files/PAD2.png" width="100%"><br></center>
        </td></tr>
        </tbody>
        </table>

        <br>
        <div style="width:900px; margin:0 auto; text-align:justify">
            The visualization of depth map on PixelAccurateDeth dataset with real foggy scenes.
        </div>
        <table align="center" width="900px">
        <tbody><tr><td align="center" width="900px">
            <center><img src="./FOggyStereo_files/Vis-4-low.png" width="100%"><br></center>
        </td></tr>
        </tbody>
        </table>

      <br>
      <hr>

    <table align="center" width="800px">
      <tbody><tr><td width="800px"><left>
      <!-- <center><h1>Acknowledgements</h1></center> -->
      Website template from <a href="https://imankgoyal.github.io/ifor.html">here</a>. <br>
      </left></td></tr>
    </tbody></table>
  <br><br>
<script xml:space="preserve" language="JavaScript">
hideallbibs();
</script>




</body><grammarly-desktop-integration data-grammarly-shadow-root="true"></grammarly-desktop-integration></html>